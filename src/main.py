from fetch_sources import fetch_all_sources
from state import load_seen_items, save_seen_items
from summarize import summarize_item
from fetch_voxeu import fetch_voxeu_papers
#from fetch_semantic_scholar import fetch_semantic_papers

def main():
    print("âœ… Bot started successfully")

    # Load previously seen research items
    seen_items = load_seen_items()

    # Fetch research from all sources (primary)
    items = fetch_all_sources()
    print(f"ğŸ“„ Fetched {len(items)} total items")

    # Filter out items that have already been sent
    new_items = [item for item in items if item["link"] not in seen_items]
    print(f"ğŸ†• {len(new_items)} new items")

    if not new_items:
        print("â„¹ï¸ No new research items today.")
    # ğŸ” FALLBACK LOGIC
    if len(new_items) == 0:
        print("âš ï¸ No items from primary sources â€” falling back to VoxEU")
        vox_items = fetch_voxeu_papers(limit=100)
        print(f"ğŸ“„ Fetched {len(vox_items)} VoxEU items")

        new_items = [
            item for item in vox_items
            if item["link"] not in seen_items
        ]

    print(f"ğŸ†• {len(new_items)} new VoxEU items")
    to_summarize = new_items[:4]
    print(f"ğŸ“Œ Summarizing {len(to_summarize)} items today (limit 4)")

    for item in to_summarize:
        print(f"[{item['source']}] {item['title']}")
        print(f"âœï¸ {item.get('authors', 'Unknown authors')}")
        print(f"ğŸ”— {item['link']}")
        if item["source"].lower().startswith("voxeu"):
            print("ğŸ“ Note: This is commentary (policy column), not peer-reviewed research.")
        # Generate summary using OpenAI
        summary = summarize_item(item)
        print(summary)
        print("-" * 60)

        # Mark item as seen
        seen_items.add(item.get('link', item.get('url')))

    # Persist updated state
    save_seen_items(seen_items)
    print("ğŸ’¾ Seen items updated successfully")


if __name__ == "__main__":
    main()
